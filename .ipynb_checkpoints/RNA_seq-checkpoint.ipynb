{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA_seq session tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan:\n",
    "\n",
    "1) Download dataset\n",
    "\n",
    "2) Read's QC\n",
    "\n",
    "3) Align reads to reference genome\n",
    "\n",
    "4) Feature count \n",
    "\n",
    "5) DE\n",
    "\n",
    "6) Pathway analysis\n",
    "\n",
    "## Download dataset\n",
    "\n",
    "Lets say that you are somehow obtain dataset. Generally, we always use GEO Datasets (https://www.ncbi.nlm.nih.gov/gds), but in this particular example we copy this GSE from server (path=`/mnt/GSE103958`).\n",
    "\n",
    "After you download this dataset you have to open repo and see what is going on. Unexpectedly, there are lots of `*.fastq.gz` files with forward and reversed reads. After several hours of brain-storming you got that each pair of reads is one sample. So you have to analyse them separatly.\n",
    "\n",
    "## QC_1\n",
    "\n",
    "In order to automate all this preprocessing phase we are going to create new `.sh` file. There are several additional bioinformatics tools requiered, so if you are trying to launch all of this on your local machine. Be sure that all the prerequisites have already installed.\n",
    "\n",
    "So all our file are in repo `GSE103958/`. All the fastqc output we will store in `fastqc/` repo.\n",
    "\n",
    "Firstly, assign variable `TAGS`, which will give you all GSM samples files names. It will be useful to us, since we are going to iterate through our dataset repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS=$(ls GSE103958/SRX*.fastq.gz | xargs -n 1 basename | sed 's/.fastq.gz//')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we are ready for iterative fastqc performing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TAG in $TAGS; do\n",
    "  OUTDIR=\"fastqc/$TAG\"; mkdir -p \"$OUTDIR\"\n",
    "  fastqc -o \"$OUTDIR\" \"GSE103958/$TAG.fastq.gz\" |& tee \"$OUTDIR/$TAG.fastqc.log\"\n",
    "done   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cycle will iterate through paths which will give you `TAGS` variable, launch fastqc and store all the output in the repo, named by sample name + `_1/2` . For example, `SRX3195600_1.fastq.gaz` will give you repo named `SRX3195600_1`. Inside this repo you can find all the bucket of fastqc files: `.log`, `.html` and `.fastqc`. If there is some error, find it in `.log`, otherwise there will be only procentage of complitence.\n",
    "\n",
    "I assume that you analyse fastqc result, trim whatever you want and make some conclusions. But I hope that everything is ok that is why we will not touch our reads. Back to them..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment\n",
    "\n",
    "So.. `hisat2`. One of the aligners. We already know `bwa`, `bowtie`, `bowtie2` etc. It is one of them. May be it is performs batter with RNA-seq data. I do not know. Whatever... we use this one. I assume that you have already know all this stuff about `.sam`/`.bam` formats, so we can skip it.\n",
    "\n",
    "As in input this tool takes our reads from `/GSE103958` folder. I assume that you analyse fastqc result, trim whatever you want and make some conclusions and hope that everything is alrignt.\n",
    "\n",
    "So.. lets launch it. Same logic. Create `TAGS` and iterate through pairs of forward/reversed reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS=$(ls fastqs/SRX31956*.fastq.gz | xargs -n 1 basename | sed 's/_[1,2].fastq.gz//' | uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TAG in $TAGS; do\n",
    "  \n",
    "  HISAT_IDX=/mnt/reference/Gencode_mouse/release_M20/GRCm38.primary_assembly\n",
    "\n",
    "  # aligning to the genome reference\n",
    "\n",
    "  OUTDIR=\"hisat2/$TAG\"; mkdir -p \"$OUTDIR\"\n",
    "  date\n",
    "  hisat2 -p 8 --new-summary -x  ${HISAT_IDX} \\\n",
    "    -1 \"GSE103958/$TAG*_1.fastq.gz\" -2 \"GSE103958/$TAG*_2.fastq.gz\" \\\n",
    "    2> \"$OUTDIR/$TAG.hisat2.log\" \\\n",
    "    | samtools view -b - > \"$OUTDIR/$TAG.mapped.raw.bam\"\n",
    "  date\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of the following loop you will get a hell of the `.bam` files. All of this will be stored in `/hisat2` repo. And again.. find all errors and statistics in `.log` files. Lets see what we got in one of them (SRX195600):\n",
    "\n",
    "```\n",
    "HISAT2 summary stats:\n",
    "\tTotal pairs: 3917883\n",
    "\t\tAligned concordantly or discordantly 0 time: 1891894 (48.29%)\n",
    "\t\tAligned concordantly 1 time: 1759408 (44.91%)\n",
    "\t\tAligned concordantly >1 times: 218967 (5.59%)\n",
    "\t\tAligned discordantly 1 time: 47614 (1.22%)\n",
    "\tTotal unpaired reads: 3783788\n",
    "\t\tAligned 0 time: 3227267 (85.29%)\n",
    "\t\tAligned 1 time: 472028 (12.48%)\n",
    "\t\tAligned >1 times: 84493 (2.23%)\n",
    "\tOverall alignment rate: 58.81%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we figure out on seminar our alignment is strand-dependent and our reversed reads are not aligned well. But what ever... Lets continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and sorting our binary files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we use the following `TAG` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS=$(ls GSE103958/SRX*.fastq.gz | xargs -n 1 basename | sed 's/_[1,2].fastq.gz//')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This commands sort our bam file (that means that it will get rid of unmapped reads) and index it (we need indexing for faster performing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TAG in $TAGS; do\n",
    "  OUTDIR=\"hisat2\";\n",
    "  date\n",
    "  samtools sort -@ 8 -O bam \"$OUTDIR/$TAG/$TAG.mapped.raw.bam\" > \"$OUTDIR/$TAG.sorted.bam\" && \\\n",
    "    samtools index \"$OUTDIR/$TAG.sorted.bam\" && \\\n",
    "  date\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an output will be pairs of `.sorted.bam` and `.bai` files (our indeces)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating coverage for vizualization\n",
    "\n",
    "* Be careful! All the subsequent commands are executed inside above `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    bamCoverage -b \"$OUTDIR/$TAG.sorted.bam\" -o \"$OUTDIR/$TAG.cov.bw\" |& tee \"$OUTDIR/$TAG.bamcov.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bamCoverage` tool takes an alignment of reads or fragments as input (BAM file) and generates a coverage track (bigWig or bedGraph) as output. The coverage is calculated as the number of reads per bin, where bins are short consecutive counting windows of a defined size (https://deeptools.readthedocs.io/en/develop/content/tools/bamCoverage.html).\n",
    "\n",
    "`.bw` contains coordinates for an interval and an associated score. The score can be anything, e.g. an average read coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside `.bam.cov.log` you can find:\n",
    "\n",
    "```\n",
    "bamFilesList: ['hisat2/SRX3195600.sorted.bam']\n",
    "binLength: 50\n",
    "numberOfSamples: None\n",
    "blackListFileName: None\n",
    "defaultFragmentLength: read length\n",
    "numberOfProcessors: 32\n",
    "verbose: False\n",
    "region: None\n",
    "bedFile: None\n",
    "minMappingQuality: None\n",
    "ignoreDuplicates: False\n",
    "chrsToSkip: []\n",
    "stepSize: 50\n",
    "center_read: False\n",
    "samFlag_include: None\n",
    "samFlag_exclude: None\n",
    "minFragmentLength: 0\n",
    "maxFragmentLength: 0\n",
    "zerosToNans: False\n",
    "smoothLength: None\n",
    "save_data: False\n",
    "out_file_for_raw_data: None\n",
    "maxPairedFragmentLength: 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC_2\n",
    "\n",
    "Here we use Alexey's scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  REFGENE_MODEL=/mnt/reference/Gencode_mouse/release_M20/mm10_Gencode_VM18.bed\n",
    "  infer_experiment.py -i \"$OUTDIR/$TAG.sorted.bam\" \\\n",
    "    -r $REFGENE_MODEL | tee \"$OUTDIR/$TAG.infer_experiment.txt\"\n",
    "\n",
    "  REFGENE_MODEL=/mnt/reference/Gencode_mouse/release_M20/mm10_Gencode_VM18.bed\n",
    "  read_distribution.py -i \"$OUTDIR/$TAG.sorted.bam\" \\\n",
    "    -r $REFGENE_MODEL | tee \"$OUTDIR/$TAG.read_distribution.txt\"\n",
    "\n",
    "  REFGENE_MODEL=/mnt/reference/Gencode_mouse/release_M20/mm10_rRNA.bed\n",
    "  split_bam.py -i \"$OUTDIR/$TAG.sorted.bam\" -r $REFGENE_MODEL -o \"$OUTDIR/$TAG.rrna\" | tee \"$OUTDIR/$TAG.split_rrna.txt\"\n",
    "  rm \"$OUTDIR/$TAG.rrna.ex.bam\" \"$OUTDIR/$TAG.rrna.in.bam\" \"$OUTDIR/$TAG.rrna.junk.bam\"\n",
    "\n",
    "  REFGENE_MODEL=/mnt/reference/Gencode_mouse/release_M20/mm10.HouseKeepingGenes.bed\n",
    "  geneBody_coverage.py \\\n",
    "    -i $OUTDIR/$TAG.sorted.bam \\\n",
    "    -o $OUTDIR/$TAG \\\n",
    "    -r $REFGENE_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer_experiment.py will give you the following information:\n",
    "\n",
    "```\n",
    "This is PairEnd Data\n",
    "Fraction of reads failed to determine: 0.0410\n",
    "Fraction of reads explained by \"1++,1--,2+-,2-+\": 0.0894\n",
    "Fraction of reads explained by \"1+-,1-+,2++,2--\": 0.8696\n",
    "```\n",
    "\n",
    "read_distribution.py:\n",
    "\n",
    "```\n",
    "Total Reads                   4608499\n",
    "Total Tags                    5288906\n",
    "Total Assigned Tags           4010886\n",
    "=====================================================================\n",
    "Group               Total_bases         Tag_count           Tags/Kb             \n",
    "CDS_Exons           36152945            931869              25.78             \n",
    "5'UTR_Exons         16406201            147564              8.99              \n",
    "3'UTR_Exons         41411212            1032599             24.94             \n",
    "Introns             1052098911          1804326             1.71              \n",
    "TSS_up_1kb          25756124            1736                0.07              \n",
    "TSS_up_5kb          117338257           4164                0.04              \n",
    "TSS_up_10kb         213767326           6233                0.03              \n",
    "TES_down_1kb        27439315            14435               0.53              \n",
    "TES_down_5kb        119238174           21495               0.18              \n",
    "TES_down_10kb       212888014           88295               0.41              \n",
    "=====================================================================\n",
    "```\n",
    "\n",
    "split_bam.py:\n",
    "\n",
    "```\n",
    "Total records: 8939588\n",
    "hisat2/SRX3195600.rrna.in.bam (Alignments consumed by input gene list): 3605928\n",
    "hisat2/SRX3195600.rrna.ex.bam (Alignments not consumed by input gene list): 2106393\n",
    "hisat2/SRX3195600.rrna.junk.bam (qcfailed, unmapped reads): 3227267\n",
    "```\n",
    "geneBody_coverage.py:\n",
    "\n",
    "```\n",
    "Percentile\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\t15\t16\t17\t18\t19\t20\t21\t22\t23\t24\t25\t26\t27\t28\t29\t30\t31\t32\t33\t34\t35\t36\t37\t38\t39\t40\t41\t42\t43\t44\t45\t46\t47\t48\t49\t50\t51\t52\t53\t54\t55\t56\t57\t58\t59\t60\t61\t62\t63\t64\t65\t66\t67\t68\t69\t70\t71\t72\t73\t74\t75\t76\t77\t78\t79\t80\t81\t82\t83\t84\t85\t86\t87\t88\t89\t90\t91\t92\t93\t94\t95\t96\t97\t98\t99\t100\n",
    "SRX3195600.sorted\t1436.0\t3070.0\t4886.0\t6775.0\t8606.0\t9914.0\t10871.0\t12150.0\t13079.0\t13182.0\t12963.0\t13176.0\t13377.0\t13660.0\t14006.0\t14357.0\t14606.0\t14569.0\t14690.0\t14784.0\t14945.0\t15069.0\t15068.0\t15177.0\t15335.0\t15049.0\t15055.0\t15204.0\t15119.0\t14885.0\t14546.0\t14638.0\t14621.0\t14850.0\t14932.0\t14983.0\t14831.0\t14864.0\t14903.0\t15111.0\t14615.0\t15005.0\t14750.0\t14507.0\t14514.0\t14404.0\t14424.0\t14313.0\t13973.0\t13818.0\t13773.0\t13641.0\t13402.0\t13076.0\t13091.0\t12924.0\t12740.0\t12457.0\t12263.0\t12794.0\t12803.0\t12636.0\t12420.0\t12229.0\t12008.0\t11753.0\t11440.0\t11469.0\t11226.0\t11071.0\t11114.0\t11036.0\t10990.0\t10817.0\t10835.0\t10739.0\t10727.0\t10468.0\t10873.0\t12539.0\t17774.0\t17699.0\t14994.0\t16426.0\t16436.0\t12081.0\t9866.0\t9343.0\t8924.0\t8675.0\t8351.0\t8002.0\t7699.0\t7478.0\t6966.0\t6493.0\t5576.0\t4612.0\t3383.0\t1871.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) `featureCounts` is a highly efficient general-purpose read summarization program that counts mapped reads for genomic features such as genes, exons, promoter, gene bodies, genomic bins and chromosomal locations. It can be used to count both RNA-seq and genomic DNA-seq reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  GTF=/mnt/reference/Gencode_mouse/release_M20/gencode.vM20.annotation.gtf\n",
    "\n",
    "  OUTDIR=\"featureCounts/$TAG\"; mkdir -p \"$OUTDIR\"\n",
    "  date\n",
    "  featureCounts -a \"$GTF\" -s 0 -o \"$OUTDIR/$TAG.fc.txt\" \\\n",
    "    \"hisat2/$TAG.sorted.bam\" |& tee \"$OUTDIR/$TAG.fc.log\"\n",
    "  date\n",
    "\n",
    "  head \"$OUTDIR/$TAG.fc.txt\"\n",
    "  wc -l \"$OUTDIR/$TAG.fc.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fc.txt.summary` contains:\n",
    "\n",
    "```\n",
    "Status\thisat2/SRX3195601.sorted.bam\n",
    "Assigned\t1923016\n",
    "Unassigned_Unmapped\t2966405\n",
    "Unassigned_MappingQuality\t0\n",
    "Unassigned_Chimera\t0\n",
    "Unassigned_FragmentLength\t0\n",
    "Unassigned_Duplicate\t0\n",
    "Unassigned_MultiMapping\t1490639\n",
    "Unassigned_Secondary\t0\n",
    "Unassigned_NonSplit\t0\n",
    "Unassigned_NoFeatures\t1756446\n",
    "Unassigned_Overlapping_Length\t0\n",
    "Unassigned_Ambiguity\t365204\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) `Kallisto` is a program for quantifying abundances of transcripts from bulk and single-cell RNA-Seq data, or more generally of target sequences using high-throughput sequencing reads. It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets, without the need for alignment. On benchmarks with standard RNA-Seq data, kallisto can quantify 30 million human reads in less than 3 minutes on a Mac desktop computer using only the read sequences and a transcriptome index that itself takes less than 10 minutes to build. Pseudoalignment of reads preserves the key information needed for quantification, and kallisto is therefore not only fast, but also as accurate as existing quantification tools. In fact, because the pseudoalignment procedure is robust to errors in the reads, in many benchmarks kallisto significantly outperforms existing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  mkdir kallisto\n",
    "\n",
    "  KALLISTO_IDX=/mnt/reference/Gencode_mouse/release_M20/gencode.vM20.transcripts.kalliso.idx\n",
    "\n",
    "  OUTDIR=\"kallisto/$TAG\"; mkdir -p \"$OUTDIR\"\n",
    "  date\n",
    "  # --single -l and -s option should be set for each dataset separately, 200+-50 is most common for single end\n",
    "  kallisto quant -i $KALLISTO_IDX -t 8 \\\n",
    "    --single -l 200 -s 50 \\\n",
    "    --plaintext \\\n",
    "    -o $OUTDIR \\\n",
    "    GSE103958/$TAG*_1.fastq.gz GSE103958/$TAG*_2.fastq.gz |& tee $OUTDIR/$TAG.kallisto.log\n",
    "  date\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.kallisto.log` contains:\n",
    "\n",
    "```\n",
    "[quant] fragment length distribution is truncated gaussian with mean = 200, sd = 50\n",
    "[index] k-mer length: 31\n",
    "[index] number of targets: 138,835\n",
    "[index] number of k-mers: 118,870,430\n",
    "[index] number of equivalence classes: 497,366\n",
    "[quant] running in single-end mode\n",
    "[quant] will process file 1: GSE103958/SRX3195600_1.fastq.gz\n",
    "[quant] will process file 2: GSE103958/SRX3195600_2.fastq.gz\n",
    "[quant] finding pseudoalignments for the reads ... done\n",
    "[quant] processed 7,835,766 reads, 2,529,134 reads pseudoaligned\n",
    "[   em] quantifying the abundances ... done\n",
    "[   em] the Expectation-Maximization algorithm ran for 917 rounds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
